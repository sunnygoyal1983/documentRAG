## DocumentRAG - sample environment file
## Copy these into your own ".env" (same folder as docker-compose.yml) if you use one.
##
## Recommended local LLM (no keys/tokens): Ollama
## If you run Ollama via docker-compose, keep OLLAMA_URL as-is.
## If you run Ollama on your host, set OLLAMA_URL=http://localhost:11434

# Local LLM configuration (Ollama)
#OLLAMA_URL=http://ollama:11434
OLLAMA_URL=http://host.docker.internal:11434
OLLAMA_MODEL=qwen2.5:14b

# Frontend -> Backend URL (when running frontend locally with Node)
NEXT_PUBLIC_API_URL=http://localhost:8000


CHUNK_MAX_CHARS=3000
MAX_CHUNKS_PER_DOC=200
EMBEDDING_BATCH_SIZE=8


# OCR (for scanned PDFs). Enable if you need it.
ENABLE_OCR=0
OCR_LANG=eng+hin+pan
OCR_TIMEOUT_S=600
OCR_MAX_PAGES=0

